{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8f85eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from Bio import SeqIO\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "import math\n",
    "import gzip\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa298bc9",
   "metadata": {},
   "source": [
    "# APOBEC mutagenesis in MPXV\n",
    "## Table of contents <a name=\"TOC\"></a>\n",
    "1. [Downloading data](#dwnl)\n",
    "2. [Plots with mutations by allele for VCF files](#vcf_allele_plots)\n",
    "3. [Comparison C>T mutations by motifs with other types of mutations](#compare)\n",
    "4. [Simulation](#simulation)\n",
    "    1. [Visualization of shares of real and simulated positions with mutations from potential ones](#shares)\n",
    "    2. [Visualization of real and simulated number of reads for targets positions by replica and time](#sim_Nreads)\n",
    "    3. [Get positions with the greatest and the least number of reads in real sample](#greatest_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b069fdf",
   "metadata": {},
   "source": [
    "## Downloading Oxford Nanopore long-read RNA-seq data from project PRJEB56841\n",
    "source - DOI: 10.1038/s41597-023-02149-4\n",
    "\n",
    "<a name='dwnl'></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "144b8868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/081/ERR10543481/ERR10543481.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/074/ERR10513574/ERR10513574.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/019/ERR10550019/ERR10550019.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/021/ERR10550021/ERR10550021.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/022/ERR10550022/ERR10550022.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/024/ERR10550024/ERR10550024.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/023/ERR10550023/ERR10550023.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/031/ERR10550031/ERR10550031.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/025/ERR10550025/ERR10550025.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/033/ERR10550033/ERR10550033.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR109/007/ERR10963107/ERR10963107.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/028/ERR10550028/ERR10550028.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR109/010/ERR10963110/ERR10963110.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR109/012/ERR10963112/ERR10963112.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR109/014/ERR10963114/ERR10963114.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/034/ERR10550034/ERR10550034.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR109/016/ERR10963116/ERR10963116.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR109/022/ERR10963122/ERR10963122.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/035/ERR10550035/ERR10550035.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR109/026/ERR10963126/ERR10963126.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR109/027/ERR10963127/ERR10963127.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR109/009/ERR10963109/ERR10963109.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR109/028/ERR10963128/ERR10963128.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR109/013/ERR10963113/ERR10963113.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR109/021/ERR10963121/ERR10963121.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR109/025/ERR10963125/ERR10963125.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/079/ERR10543479/ERR10543479.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/080/ERR10543480/ERR10543480.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/020/ERR10550020/ERR10550020.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/026/ERR10550026/ERR10550026.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/027/ERR10550027/ERR10550027.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/029/ERR10550029/ERR10550029.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/030/ERR10550030/ERR10550030.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/032/ERR10550032/ERR10550032.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR105/036/ERR10550036/ERR10550036.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR109/008/ERR10963108/ERR10963108.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR109/011/ERR10963111/ERR10963111.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR109/015/ERR10963115/ERR10963115.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR109/017/ERR10963117/ERR10963117.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR109/018/ERR10963118/ERR10963118.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR109/019/ERR10963119/ERR10963119.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR109/020/ERR10963120/ERR10963120.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR109/023/ERR10963123/ERR10963123.fastq.gz ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR109/024/ERR10963124/ERR10963124.fastq.gz'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list with samples paths for downloading (PRJEB56841 project)\n",
    "df = pd.read_csv('filereport_read_run_PRJEB56841_tsv.txt', sep='\\t')\n",
    "fastq_ftp = df.fastq_ftp.to_list()\n",
    "fastq_ftp = [\"ftp://\"+i for i in fastq_ftp]\n",
    "' '.join(fastq_ftp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8a33ef",
   "metadata": {},
   "source": [
    "script for downloading samples and mapping to the genome: scripts/RNAseq_MPXV_downl_process.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7a0b40",
   "metadata": {},
   "source": [
    "script for searching SNP in BAM files: scripts/clair3.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3a5b0a",
   "metadata": {},
   "source": [
    "## Plots with mutations by allele for VCF files \n",
    "\n",
    "<a name='vcf_allele_plots'></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2864de34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ERR10550019': 'MPOX_inf_1h_A_pass', 'ERR10963107': 'MPOX_inf_1h_A_pass', 'ERR10550020': 'MPOX_inf_1h_B_pass', 'ERR10963108': 'MPOX_inf_1h_B_pass', 'ERR10550021': 'MPOX_inf_1h_C_pass', 'ERR10963109': 'MPOX_inf_1h_C_pass', 'ERR10550022': 'MPOX_inf_2h_A_pass', 'ERR10963110': 'MPOX_inf_2h_A_pass', 'ERR10550023': 'MPOX_inf_2h_B_pass', 'ERR10963111': 'MPOX_inf_2h_B_pass', 'ERR10550024': 'MPOX_inf_2h_C_pass', 'ERR10963112': 'MPOX_inf_2h_C_pass', 'ERR10550025': 'MPOX_inf_4h_A_pass', 'ERR10963113': 'MPOX_inf_4h_A_pass', 'ERR10550026': 'MPOX_inf_4h_B_pass', 'ERR10963114': 'MPOX_inf_4h_B_pass', 'ERR10550027': 'MPOX_inf_4h_C_pass', 'ERR10963115': 'MPOX_inf_4h_C_pass', 'ERR10550028': 'MPOX_inf_6h_A_pass', 'ERR10963116': 'MPOX_inf_6h_A_pass', 'ERR10550029': 'MPOX_inf_6h_B_pass', 'ERR10963117': 'MPOX_inf_6h_B_pass', 'ERR10550030': 'MPOX_inf_6h_C_pass', 'ERR10963118': 'MPOX_inf_6h_C_pass', 'ERR10543479': 'MPOX_inf_12h_A_pass', 'ERR10963119': 'MPOX_inf_12h_A_pass', 'ERR10543480': 'MPOX_inf_12h_B_pass', 'ERR10963120': 'MPOX_inf_12h_B_pass', 'ERR10543481': 'MPOX_inf_12h_C_pass', 'ERR10963121': 'MPOX_inf_12h_C_pass', 'ERR10550031': 'MPOX_inf_24h_A_pass', 'ERR10963122': 'MPOX_inf_24h_A_pass', 'ERR10550032': 'MPOX_inf_24h_B_pass', 'ERR10963123': 'MPOX_inf_24h_B_pass', 'ERR10550033': 'MPOX_inf_24h_C_pass', 'ERR10963124': 'MPOX_inf_24h_C_pass', 'ERR10550034': 'MPOX_mock_A_pass', 'ERR10963125': 'MPOX_mock_A_pass', 'ERR10550035': 'MPOX_mock_B_pass', 'ERR10963126': 'MPOX_mock_B_pass', 'ERR10550036': 'MPOX_mock_C_pass', 'ERR10963127': 'MPOX_mock_C_pass', 'ERR10513574': 'MPOX_dRNA_inf_pass', 'ERR10963128': 'MPOX_dRNA_inf_pass'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "fig_list = ['Nreads', 'freq']\n",
    "align_method = 'minimap2'\n",
    "\n",
    "##min and max for variant frequency\n",
    "min_VF = 0.001\n",
    "max_VF = 0.9\n",
    "\n",
    "##read genome file\n",
    "###to find position in genome: str(genome_dict['NC_045512.2'].seq)\n",
    "genome_file = open(r\"\\NC_063383.1.fasta\")\n",
    "genome_dict = SeqIO.to_dict(SeqIO.parse(genome_file, \"fasta\"))\n",
    "\n",
    "##palette for pictures\n",
    "colors_list = ['#C6878F', '#3D405B', '#81B29A', '#E07A5F', '#5F797B', '#F2CC8F']\n",
    "\n",
    "#samples description: replica, time and file type\n",
    "## table source - DOI: 10.1038/s41597-023-02149-4 \n",
    "samples_features = pd.read_excel(r\"\\41597_2023_2149_MOESM2_ESM.xlsx\", skiprows=2)\n",
    "samples_features = samples_features.fillna(method='ffill', axis=0)\n",
    "samples_features.head()\n",
    "\n",
    "samples_features_dict = samples_features.set_index('Run accession')['Library Name'].to_dict()\n",
    "print(samples_features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea91df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to rounding up top position\n",
    "def round_up(n, decimals=0):\n",
    "    multiplier = 10**decimals\n",
    "    return math.ceil(n * multiplier) / multiplier\n",
    "\n",
    "def get_plot_vcf(vcf_file, ID, feature_sample, method=align_method, min_vf=min_VF, max_vf=max_VF, genome=str(genome_dict['NC_063383.1'].seq), colors=colors_list):\n",
    "    \n",
    "    ##read vcf file\n",
    "    ##skip description in vcf file\n",
    "    with open(vcf_file, 'r') as f:\n",
    "        reader=f.readlines()\n",
    "        row = 0\n",
    "        while reader[row].startswith('##') == True:\n",
    "            row += 1\n",
    "    df_vcf = pd.read_csv(vcf_file, skiprows=row, sep='\\t')\n",
    "    df_vcf = df_vcf.dropna()\n",
    "    \n",
    "    ##make dataframe from vcf file\n",
    "    ###list with all allele variants of 3 nucleotides\n",
    "    A = ['A'.join(i) for i in itertools.product('ATCG', repeat=2)]\n",
    "    T = ['T'.join(i) for i in itertools.product('ATCG', repeat=2)]\n",
    "    C = ['C'.join(i) for i in itertools.product('ATCG', repeat=2)]\n",
    "    G = ['G'.join(i) for i in itertools.product('ATCG', repeat=2)]\n",
    "    allele_list = A + T + C + G\n",
    "\n",
    "    ###dataframe for counting reads number for mutations\n",
    "    df_Nreads = pd.DataFrame(columns=['ref_nucl', 'allele', 'A', 'T', 'C', 'G'])\n",
    "    df_Nreads['ref_nucl'] = ['A']*16 + ['T']*16 + ['C']*16 + ['G']*16\n",
    "    df_Nreads['allele'] = allele_list\n",
    "    df_Nreads = df_Nreads.set_index('allele')\n",
    "    df_Nreads.fillna(0, inplace=True)\n",
    "    ###replace cells with no mutation (like A>A) with NaN\n",
    "    for nucl in ['A', 'T', 'C', 'G']:\n",
    "        df_Nreads.loc[df_Nreads['ref_nucl'] == nucl, nucl] = np.nan\n",
    "    \n",
    "    ###dataframe for counting allele's frequencies for mutations\n",
    "    df_freq = pd.DataFrame(columns=['ref_nucl', 'allele', 'A', 'T', 'C', 'G'])\n",
    "    df_freq['ref_nucl'] = ['A']*16 + ['T']*16 + ['C']*16 + ['G']*16\n",
    "    df_freq['allele'] = allele_list\n",
    "    df_freq = df_freq.set_index('allele')\n",
    "    df_freq.fillna(0, inplace=True)\n",
    "    ###replace cells with no mutation (like A>A) with NaN\n",
    "    for nucl in ['A', 'T', 'C', 'G']:\n",
    "        df_freq.loc[df_freq['ref_nucl'] == nucl, nucl] = np.nan\n",
    "        \n",
    "\n",
    "    for row in range(0, len(df_vcf)):\n",
    "        mutation_pos = df_vcf.loc[row, 'POS'] - 1\n",
    "        allele = genome[mutation_pos-1:mutation_pos+2]\n",
    "        alt_nucl = df_vcf.loc[row, 'ALT']\n",
    "        if (len(alt_nucl) != 1) or (len(df_vcf.loc[row, 'REF']) != 1) or (len(allele) != 3):\n",
    "            continue\n",
    "\n",
    "        ###Allele Depth (AD) in vcf file: first number - number of reads with ref nucl, second - with alt nucl (Nreads_alt)\n",
    "        FORMAT = df_vcf.iloc[row, -2].split(':')\n",
    "        AD_ind = FORMAT.index('AD')\n",
    "        AF_ind = FORMAT.index('AF')\n",
    "        AD = df_vcf.iloc[row, -1].split(':')[AD_ind]\n",
    "        Nreads_alt = int(AD.split(',')[1])\n",
    "        AF = df_vcf.iloc[row, -1].split(':')[AF_ind]\n",
    "        freq = float(AF)\n",
    "        if freq >= min_vf and freq < max_vf:\n",
    "            df_Nreads.at[allele, alt_nucl] += Nreads_alt\n",
    "            df_freq.at[allele, alt_nucl] += freq\n",
    "        \n",
    "    \n",
    "    df_Nreads.reset_index(inplace=True)\n",
    "    df_Nreads = df_Nreads.set_index(['allele'])\n",
    "    df_Nreads = df_Nreads[['A', 'T', 'C', 'G']].stack()\n",
    "    df_Nreads = df_Nreads.to_frame().reset_index()\n",
    "    df_Nreads = df_Nreads.dropna()\n",
    "    df_Nreads = df_Nreads.rename(columns={\"level_1\": \"ALT\", 0:'Nreads'})\n",
    "    df_Nreads['REF'] = df_Nreads['allele'].apply(lambda x: x[1])\n",
    "    df_Nreads['mutation'] = df_Nreads['REF'] + '>' + df_Nreads['ALT']\n",
    "    df_Nreads = df_Nreads[['allele', 'REF', 'ALT', 'mutation', 'Nreads']]\n",
    "    df_Nreads = df_Nreads.sort_values(by=['mutation', 'allele'])\n",
    "    df_Nreads = df_Nreads.reset_index(drop=True)\n",
    "    \n",
    "    df_freq.reset_index(inplace=True)\n",
    "    df_freq = df_freq.set_index(['allele'])\n",
    "    df_freq = df_freq[['A', 'T', 'C', 'G']].stack()\n",
    "    df_freq = df_freq.to_frame().reset_index()\n",
    "    df_freq = df_freq.dropna()\n",
    "    df_freq = df_freq.rename(columns={\"level_1\": \"ALT\", 0:'freq'})\n",
    "    df_freq['REF'] = df_freq['allele'].apply(lambda x: x[1])\n",
    "    df_freq['mutation'] = df_freq['REF'] + '>' + df_freq['ALT']\n",
    "    df_freq = df_freq[['allele', 'REF', 'ALT', 'mutation', 'freq']]\n",
    "    df_freq = df_freq.sort_values(by=['mutation', 'allele'])\n",
    "    df_freq = df_freq.reset_index(drop=True)\n",
    "\n",
    "    #make picture\n",
    "    custom_palette = []\n",
    "    for x in colors:\n",
    "        custom_palette.extend([x]*16)\n",
    "    ##divide dataframe into two parts\n",
    "    df1_Nreads = df_Nreads[df_Nreads['REF'].isin(['A', 'C'])]\n",
    "    df2_Nreads = df_Nreads[df_Nreads['REF'].isin(['G', 'T'])]\n",
    "    df1_freq = df_freq[df_freq['REF'].isin(['A', 'C'])]\n",
    "    df2_freq = df_freq[df_freq['REF'].isin(['G', 'T'])]\n",
    "\n",
    "    mutation_list1 = df1_Nreads.mutation.to_list()\n",
    "    mutation_list1 = list(set(mutation_list1))\n",
    "    mutation_list1.sort()\n",
    "    mutation_list2 = df2_Nreads.mutation.to_list()\n",
    "    mutation_list2 = list(set(mutation_list2))\n",
    "    mutation_list2.sort()\n",
    "\n",
    "    ###picture for number of reads\n",
    "    fig1 = plt.figure(figsize=(16, 7))\n",
    "    ax11 = plt.subplot2grid(shape=(2, 1), loc=(0, 0))\n",
    "    ax12 = plt.subplot2grid(shape=(2, 1), loc=(1, 0))\n",
    "\n",
    "    ax11 = sns.barplot(x=df1_Nreads.index, y=df1_Nreads.Nreads, palette=custom_palette, ax=ax11)\n",
    "    ax12 = sns.barplot(x=df2_Nreads.index, y=df2_Nreads.Nreads, palette=custom_palette, ax=ax12)\n",
    "    ax11.set_xticklabels(df1_Nreads.allele, rotation=90, horizontalalignment='center')\n",
    "    ax12.set_xticklabels(df2_Nreads.allele, rotation=90, horizontalalignment='center')\n",
    "\n",
    "    ####change lim of picture\n",
    "    top_position = int(df_Nreads.Nreads.max())\n",
    "    round_pos = 0\n",
    "    while top_position >= 10:\n",
    "        top_position = int(top_position / 10)\n",
    "        round_pos += 1\n",
    "    new_top_position = round_up(df_Nreads.Nreads.max(), -round_pos)\n",
    "\n",
    "    ####rectangle must place 10% of space\n",
    "    part_ten = int(new_top_position/10)\n",
    "    ax11.set_ylim(0, new_top_position+part_ten)\n",
    "    ax12.set_ylim(0, new_top_position+part_ten)\n",
    "\n",
    "    ####add rectangles\n",
    "    for i in range(0, len(colors)):\n",
    "        ax11.add_patch(Rectangle((i*16, new_top_position), 16, part_ten, facecolor = colors[i]))\n",
    "        ax11.text(i*16+8, new_top_position+int(part_ten/2), mutation_list1[i], horizontalalignment='center', verticalalignment='center', size='x-large', color='white', weight='semibold')\n",
    "        ax12.add_patch(Rectangle((i*16, new_top_position), 16, part_ten, facecolor = colors[i]))\n",
    "        ax12.text(i*16+8, new_top_position+int(part_ten/2), mutation_list2[i], horizontalalignment='center', verticalalignment='center', size='x-large', color='white', weight='semibold')\n",
    "\n",
    "    ####save picture\n",
    "    fig1.suptitle('Number of reads by mutation type for sample '+ID+', '+feature_sample+'\\naligned using '+method, fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.close(fig1)\n",
    "\n",
    "\n",
    "    ###picture for freq\n",
    "    fig2 = plt.figure(figsize=(16, 7))\n",
    "    ax21 = plt.subplot2grid(shape=(2, 1), loc=(0, 0))\n",
    "    ax22 = plt.subplot2grid(shape=(2, 1), loc=(1, 0))\n",
    "\n",
    "    ax21 = sns.barplot(x=df1_freq.index, y=df1_freq.freq, palette=custom_palette, ax=ax21)\n",
    "    ax22 = sns.barplot(x=df2_freq.index, y=df2_freq.freq, palette=custom_palette, ax=ax22)\n",
    "    ax21.set_xticklabels(df1_freq.allele, rotation=90, horizontalalignment='center')\n",
    "    ax22.set_xticklabels(df2_freq.allele, rotation=90, horizontalalignment='center')\n",
    "\n",
    "    ####change lim of picture\n",
    "    top_position = df_freq.freq.max()\n",
    "    if top_position >= 1:\n",
    "        new_top_position = top_position + 0.1\n",
    "    else:\n",
    "        round_pos = 0\n",
    "        while top_position < 1:\n",
    "            top_position = top_position * 10\n",
    "            round_pos += 1\n",
    "        new_top_position = round_up(df_freq.freq.max(), round_pos)\n",
    "        \n",
    "\n",
    "    ####rectangle must place 10% of space\n",
    "    part_ten = new_top_position/10\n",
    "    ax21.set_ylim(0, new_top_position+part_ten)\n",
    "    ax22.set_ylim(0, new_top_position+part_ten)\n",
    "    \n",
    "\n",
    "    ####add rectangles\n",
    "    for i in range(0, len(colors)):\n",
    "        ax21.add_patch(Rectangle((i*16, new_top_position), 16, part_ten, facecolor = colors[i]))\n",
    "        ax21.text(i*16+8, new_top_position+part_ten/2, mutation_list1[i], horizontalalignment='center', verticalalignment='center', size='x-large', color='white', weight='semibold')\n",
    "        ax22.add_patch(Rectangle((i*16, new_top_position), 16, part_ten, facecolor = colors[i]))\n",
    "        ax22.text(i*16+8, new_top_position+part_ten/2, mutation_list2[i], horizontalalignment='center', verticalalignment='center', size='x-large', color='white', weight='semibold')\n",
    "\n",
    "    fig2.suptitle('Allele frequency by mutation type for sample '+ID+', '+feature_sample+'\\naligned using '+method, fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.close(fig2)\n",
    "    \n",
    "    return [fig1, fig2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e130a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERR10513574, ERR10543479, ERR10543480, ERR10543481, ERR10550019, ERR10550020, ERR10550021, ERR10550022, ERR10550023, ERR10550024, ERR10550025, ERR10550026, ERR10550027, ERR10550028, ERR10550029, ERR10550030, ERR10550031, ERR10550032, ERR10550033, ERR10550034, ERR10550035, ERR10550036, ERR10963107, ERR10963108, ERR10963109, ERR10963110, ERR10963111, ERR10963112, ERR10963113, ERR10963114, ERR10963115, ERR10963116, ERR10963117, ERR10963118, ERR10963119, ERR10963120, ERR10963121, ERR10963122, ERR10963123, ERR10963124, ERR10963125, ERR10963126, ERR10963127, ERR10963128, "
     ]
    }
   ],
   "source": [
    "# path to directory with vcf files\n",
    "directory = r\"\\MPXV\\clair3_vcf\"\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if f.endswith(\".bam\"):\n",
    "        bam_path = f\n",
    "        vcf_file = os.path.join(bam_path, \"merge_output.vcf\")\n",
    "        sample_id = filename[:-4]\n",
    "        \n",
    "        #features from file 41597_2023_2149_MOESM2_ESM.xlsx\n",
    "        feature = samples_features_dict[sample_id]\n",
    "        feature = feature[5:]\n",
    "        feature = feature.replace('_pass', '')\n",
    "        print(sample_id, end=', ')\n",
    "        plot_list = get_plot_vcf(vcf_file, sample_id, feature)\n",
    "        for i in range(0, len(plot_list)):\n",
    "            plot_list[i].savefig(directory+'/pictures/'+sample_id+'_'+feature+'_'+fig_list[i]+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36396f00",
   "metadata": {},
   "source": [
    "Pictures are available https://drive.google.com/file/d/16i0P8gNPb4JL6YCDeZRfEDB77ym-wwaf/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd743788",
   "metadata": {},
   "source": [
    "## Comparison C>T mutations by motifs with other types of mutations\n",
    "\n",
    "<a name='compare'></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "592802c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>group</th>\n",
       "      <th>file_type</th>\n",
       "      <th>allele</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ERR10550019</th>\n",
       "      <td>1h</td>\n",
       "      <td>A</td>\n",
       "      <td>bam</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10963107</th>\n",
       "      <td>1h</td>\n",
       "      <td>A</td>\n",
       "      <td>fastq.gz</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10550020</th>\n",
       "      <td>1h</td>\n",
       "      <td>B</td>\n",
       "      <td>bam</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10963108</th>\n",
       "      <td>1h</td>\n",
       "      <td>B</td>\n",
       "      <td>fastq.gz</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10550021</th>\n",
       "      <td>1h</td>\n",
       "      <td>C</td>\n",
       "      <td>bam</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time group file_type allele\n",
       "ERR10550019   1h     A       bam       \n",
       "ERR10963107   1h     A  fastq.gz       \n",
       "ERR10550020   1h     B       bam       \n",
       "ERR10963108   1h     B  fastq.gz       \n",
       "ERR10550021   1h     C       bam       "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_filtering_function(pair):\n",
    "    key, value = pair\n",
    "    if \"dRNA\" in value or \"mock\" in value:\n",
    "        return False  # keep pair in the filtered dictionary\n",
    "    else:\n",
    "        return True  # filter pair out of the dictionary\n",
    "\n",
    "directory = r\"\\PRJEB56841\"\n",
    "\n",
    "#samples features\n",
    "## table source - DOI: 10.1038/s41597-023-02149-4\n",
    "samples_features = pd.read_excel(r\"\\41597_2023_2149_MOESM2_ESM.xlsx\", skiprows=2)\n",
    "samples_features = samples_features.fillna(method='ffill', axis=0)\n",
    "samples_features.head()\n",
    "\n",
    "samples_features_dict = samples_features.set_index('Run accession')['File names'].to_dict()\n",
    "\n",
    "#filter mock and dRNA\n",
    "filtered_samples_features = dict(filter(my_filtering_function, samples_features_dict.items()))\n",
    " \n",
    "for key, value in filtered_samples_features.items():\n",
    "    new_value = value.split('_')[2:]\n",
    "    new_value[2] = new_value[2][5:]\n",
    "    filtered_samples_features[key] = new_value\n",
    "res = pd.DataFrame.from_dict(filtered_samples_features,orient='index', columns=['time', 'group', 'file_type'])\n",
    "res['allele'] = ''\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09e62c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "##min and max for variant frequency\n",
    "min_VF = 0.001\n",
    "max_VF = 0.9\n",
    "\n",
    "##read genome file\n",
    "##to find position in genome: str(genome_dict['NC_045512.2'].seq)\n",
    "genome_file = open(r\"\\NC_063383.1.fasta\")\n",
    "genome_dict = SeqIO.to_dict(SeqIO.parse(genome_file, \"fasta\"))\n",
    "\n",
    "##mutations categories\n",
    "category_list = ['TCT', 'TCA', 'TCC', 'TCG', '*']\n",
    "category_complement_list = ['AGA', 'TGA', 'GGA', 'CGA', '*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9ede139",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to rounding up top position\n",
    "def round_up(n, decimals=0):\n",
    "    multiplier = 10**decimals\n",
    "    return math.ceil(n * multiplier) / multiplier\n",
    "\n",
    "def Nread_freq_by_category(vcf_file, category = category_list, category_complement = category_complement_list, min_vf=min_VF, max_vf=max_VF, genome=str(genome_dict['NC_063383.1'].seq)):\n",
    "    \n",
    "    ##read vcf file\n",
    "    ##skip description in vcf file\n",
    "    with open(vcf_file, 'r') as f:\n",
    "        reader=f.readlines()\n",
    "        row = 0\n",
    "        while reader[row].startswith('##') == True:\n",
    "            row += 1\n",
    "    df_vcf = pd.read_csv(vcf_file, skiprows=row, sep='\\t')\n",
    "    df_vcf = df_vcf.dropna()\n",
    "    \n",
    "    ##make dataframe from vcf file\n",
    "    ###list with all allele variants of 3 nucleotides\n",
    "    A = ['A'.join(i) for i in itertools.product('ATCG', repeat=2)]\n",
    "    T = ['T'.join(i) for i in itertools.product('ATCG', repeat=2)]\n",
    "    C = ['C'.join(i) for i in itertools.product('ATCG', repeat=2)]\n",
    "    G = ['G'.join(i) for i in itertools.product('ATCG', repeat=2)]\n",
    "    allele_list = A + T + C + G\n",
    "\n",
    "    ###dataframe for counting reads number for mutations\n",
    "    df_Nreads = pd.DataFrame(columns=['ref_nucl', 'allele', 'A', 'T', 'C', 'G'])\n",
    "    df_Nreads['ref_nucl'] = ['A']*16 + ['T']*16 + ['C']*16 + ['G']*16\n",
    "    df_Nreads['allele'] = allele_list\n",
    "    df_Nreads = df_Nreads.set_index('allele')\n",
    "    df_Nreads.fillna(0, inplace=True)\n",
    "    ###replace cells with no mutation (like A>A) with NaN\n",
    "    for nucl in ['A', 'T', 'C', 'G']:\n",
    "        df_Nreads.loc[df_Nreads['ref_nucl'] == nucl, nucl] = np.nan\n",
    "    \n",
    "    ###dataframe for counting allele's frequencies for mutations\n",
    "    df_freq = pd.DataFrame(columns=['ref_nucl', 'allele', 'A', 'T', 'C', 'G'])\n",
    "    df_freq['ref_nucl'] = ['A']*16 + ['T']*16 + ['C']*16 + ['G']*16\n",
    "    df_freq['allele'] = allele_list\n",
    "    df_freq = df_freq.set_index('allele')\n",
    "    df_freq.fillna(0, inplace=True)\n",
    "    ###replace cells with no mutation (like A>A) with NaN\n",
    "    for nucl in ['A', 'T', 'C', 'G']:\n",
    "        df_freq.loc[df_freq['ref_nucl'] == nucl, nucl] = np.nan\n",
    "        \n",
    "\n",
    "    for row in range(0, len(df_vcf)):\n",
    "        mutation_pos = df_vcf.loc[row, 'POS'] - 1\n",
    "        allele = genome[mutation_pos-1:mutation_pos+2]\n",
    "        alt_nucl = df_vcf.loc[row, 'ALT']\n",
    "        if (len(alt_nucl) != 1) or (len(df_vcf.loc[row, 'REF']) != 1) or (len(allele) != 3):\n",
    "            continue\n",
    "\n",
    "        ###Allele Depth (AD) in vcf file: first number - number of reads with ref nucl, second - with alt nucl (Nreads_alt)\n",
    "        FORMAT = df_vcf.iloc[row, -2].split(':')\n",
    "        AD_ind = FORMAT.index('AD')\n",
    "        AF_ind = FORMAT.index('AF')\n",
    "        AD = df_vcf.iloc[row, -1].split(':')[AD_ind]\n",
    "        Nreads_alt = int(AD.split(',')[1])\n",
    "        AF = df_vcf.iloc[row, -1].split(':')[AF_ind]\n",
    "        freq = float(AF)\n",
    "        if freq >= min_vf and freq < max_vf:\n",
    "            df_Nreads.at[allele, alt_nucl] += Nreads_alt\n",
    "            df_freq.at[allele, alt_nucl] += freq\n",
    "        \n",
    "    \n",
    "    df_Nreads.reset_index(inplace=True)\n",
    "    df_Nreads = df_Nreads.set_index(['allele'])\n",
    "    df_Nreads = df_Nreads[['A', 'T', 'C', 'G']].stack()\n",
    "    df_Nreads = df_Nreads.to_frame().reset_index()\n",
    "    df_Nreads = df_Nreads.dropna()\n",
    "    df_Nreads = df_Nreads.rename(columns={\"level_1\": \"ALT\", 0:'Nreads'})\n",
    "    df_Nreads['REF'] = df_Nreads['allele'].apply(lambda x: x[1])\n",
    "    df_Nreads['mutation'] = df_Nreads['REF'] + '>' + df_Nreads['ALT']\n",
    "    df_Nreads = df_Nreads[['allele', 'REF', 'ALT', 'mutation', 'Nreads']]\n",
    "    df_Nreads = df_Nreads.sort_values(by=['mutation', 'allele'])\n",
    "    df_Nreads = df_Nreads.reset_index(drop=True)\n",
    "    \n",
    "    #count for category\n",
    "    Nreads = []\n",
    "    for i in range(0, len(category[:-1])):\n",
    "        motif = category[i]\n",
    "        motif_complement = category_complement[i]\n",
    "        Nr1 = df_Nreads[(df_Nreads['allele'] == motif) & (df_Nreads['mutation'] == 'C>T')]['Nreads'].sum()\n",
    "        Nr2 = df_Nreads[(df_Nreads['allele'] == motif_complement) & (df_Nreads['mutation'] == 'G>A')]['Nreads'].sum()\n",
    "        Nreads.append(Nr1+Nr2)\n",
    "    Nreads.append(df_Nreads['Nreads'].sum() - sum(Nreads))\n",
    "    \n",
    "    df_freq.reset_index(inplace=True)\n",
    "    df_freq = df_freq.set_index(['allele'])\n",
    "    df_freq = df_freq[['A', 'T', 'C', 'G']].stack()\n",
    "    df_freq = df_freq.to_frame().reset_index()\n",
    "    df_freq = df_freq.dropna()\n",
    "    df_freq = df_freq.rename(columns={\"level_1\": \"ALT\", 0:'freq'})\n",
    "    df_freq['REF'] = df_freq['allele'].apply(lambda x: x[1])\n",
    "    df_freq['mutation'] = df_freq['REF'] + '>' + df_freq['ALT']\n",
    "    df_freq = df_freq[['allele', 'REF', 'ALT', 'mutation', 'freq']]\n",
    "    df_freq = df_freq.sort_values(by=['mutation', 'allele'])\n",
    "    df_freq = df_freq.reset_index(drop=True)\n",
    "    \n",
    "    #count for category\n",
    "    freq = []\n",
    "    for i in range(0, len(category[:-1])):\n",
    "        motif = category[i]\n",
    "        motif_complement = category_complement[i]\n",
    "        freq1 = df_freq[(df_freq['allele'] == motif) & (df_freq['mutation'] == 'C>T')]['freq'].sum()\n",
    "        freq2 = df_freq[(df_freq['allele'] == motif_complement) & (df_freq['mutation'] == 'G>A')]['freq'].sum()\n",
    "        freq.append(freq1+freq2)\n",
    "    freq.append(df_freq['freq'].sum() - sum(freq))\n",
    "    \n",
    "    new_list=[]\n",
    "    for i in range(0, len(category)):\n",
    "        new_list.append([category[i]]+[Nreads[i]]+[freq[i]])\n",
    "    \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2d9a8c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>group</th>\n",
       "      <th>file_type</th>\n",
       "      <th>allele</th>\n",
       "      <th>Nreads</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ERR10550019</th>\n",
       "      <td>1h</td>\n",
       "      <td>A</td>\n",
       "      <td>bam</td>\n",
       "      <td>TCT</td>\n",
       "      <td>151.0</td>\n",
       "      <td>3.8339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10550019</th>\n",
       "      <td>1h</td>\n",
       "      <td>A</td>\n",
       "      <td>bam</td>\n",
       "      <td>TCA</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.9896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10550019</th>\n",
       "      <td>1h</td>\n",
       "      <td>A</td>\n",
       "      <td>bam</td>\n",
       "      <td>TCC</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.7451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10550019</th>\n",
       "      <td>1h</td>\n",
       "      <td>A</td>\n",
       "      <td>bam</td>\n",
       "      <td>TCG</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.2864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10550019</th>\n",
       "      <td>1h</td>\n",
       "      <td>A</td>\n",
       "      <td>bam</td>\n",
       "      <td>*</td>\n",
       "      <td>657.0</td>\n",
       "      <td>32.1077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10963107</th>\n",
       "      <td>1h</td>\n",
       "      <td>A</td>\n",
       "      <td>fastq.gz</td>\n",
       "      <td>TCT</td>\n",
       "      <td>151.0</td>\n",
       "      <td>3.8339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10963107</th>\n",
       "      <td>1h</td>\n",
       "      <td>A</td>\n",
       "      <td>fastq.gz</td>\n",
       "      <td>TCA</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4.7229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10963107</th>\n",
       "      <td>1h</td>\n",
       "      <td>A</td>\n",
       "      <td>fastq.gz</td>\n",
       "      <td>TCC</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.7451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10963107</th>\n",
       "      <td>1h</td>\n",
       "      <td>A</td>\n",
       "      <td>fastq.gz</td>\n",
       "      <td>TCG</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.2864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10963107</th>\n",
       "      <td>1h</td>\n",
       "      <td>A</td>\n",
       "      <td>fastq.gz</td>\n",
       "      <td>*</td>\n",
       "      <td>684.0</td>\n",
       "      <td>33.7102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10550020</th>\n",
       "      <td>1h</td>\n",
       "      <td>B</td>\n",
       "      <td>bam</td>\n",
       "      <td>TCT</td>\n",
       "      <td>160.0</td>\n",
       "      <td>3.7609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10550020</th>\n",
       "      <td>1h</td>\n",
       "      <td>B</td>\n",
       "      <td>bam</td>\n",
       "      <td>TCA</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3.0442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10550020</th>\n",
       "      <td>1h</td>\n",
       "      <td>B</td>\n",
       "      <td>bam</td>\n",
       "      <td>TCC</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.7857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10550020</th>\n",
       "      <td>1h</td>\n",
       "      <td>B</td>\n",
       "      <td>bam</td>\n",
       "      <td>TCG</td>\n",
       "      <td>174.0</td>\n",
       "      <td>4.9713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10550020</th>\n",
       "      <td>1h</td>\n",
       "      <td>B</td>\n",
       "      <td>bam</td>\n",
       "      <td>*</td>\n",
       "      <td>609.0</td>\n",
       "      <td>31.8755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10963108</th>\n",
       "      <td>1h</td>\n",
       "      <td>B</td>\n",
       "      <td>fastq.gz</td>\n",
       "      <td>TCT</td>\n",
       "      <td>160.0</td>\n",
       "      <td>3.7609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10963108</th>\n",
       "      <td>1h</td>\n",
       "      <td>B</td>\n",
       "      <td>fastq.gz</td>\n",
       "      <td>TCA</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.2442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10963108</th>\n",
       "      <td>1h</td>\n",
       "      <td>B</td>\n",
       "      <td>fastq.gz</td>\n",
       "      <td>TCC</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.7351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10963108</th>\n",
       "      <td>1h</td>\n",
       "      <td>B</td>\n",
       "      <td>fastq.gz</td>\n",
       "      <td>TCG</td>\n",
       "      <td>173.0</td>\n",
       "      <td>4.4713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10963108</th>\n",
       "      <td>1h</td>\n",
       "      <td>B</td>\n",
       "      <td>fastq.gz</td>\n",
       "      <td>*</td>\n",
       "      <td>598.0</td>\n",
       "      <td>31.3424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time group file_type allele  Nreads     freq\n",
       "ERR10550019   1h     A       bam    TCT   151.0   3.8339\n",
       "ERR10550019   1h     A       bam    TCA    51.0   3.9896\n",
       "ERR10550019   1h     A       bam    TCC    16.0   1.7451\n",
       "ERR10550019   1h     A       bam    TCG    21.0   3.2864\n",
       "ERR10550019   1h     A       bam      *   657.0  32.1077\n",
       "ERR10963107   1h     A  fastq.gz    TCT   151.0   3.8339\n",
       "ERR10963107   1h     A  fastq.gz    TCA    54.0   4.7229\n",
       "ERR10963107   1h     A  fastq.gz    TCC    16.0   1.7451\n",
       "ERR10963107   1h     A  fastq.gz    TCG    21.0   3.2864\n",
       "ERR10963107   1h     A  fastq.gz      *   684.0  33.7102\n",
       "ERR10550020   1h     B       bam    TCT   160.0   3.7609\n",
       "ERR10550020   1h     B       bam    TCA    59.0   3.0442\n",
       "ERR10550020   1h     B       bam    TCC    11.0   0.7857\n",
       "ERR10550020   1h     B       bam    TCG   174.0   4.9713\n",
       "ERR10550020   1h     B       bam      *   609.0  31.8755\n",
       "ERR10963108   1h     B  fastq.gz    TCT   160.0   3.7609\n",
       "ERR10963108   1h     B  fastq.gz    TCA    60.0   3.2442\n",
       "ERR10963108   1h     B  fastq.gz    TCC    19.0   1.7351\n",
       "ERR10963108   1h     B  fastq.gz    TCG   173.0   4.4713\n",
       "ERR10963108   1h     B  fastq.gz      *   598.0  31.3424"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf_dir = r\"\\clair3_vcf\\vcf\"\n",
    "\n",
    "for key in filtered_samples_features:\n",
    "    VCF_FILE = os.path.join(vcf_dir, key+'.vcf')\n",
    "    res.loc[key]['allele'] = Nread_freq_by_category(VCF_FILE)\n",
    "\n",
    "#transform table\n",
    "transformed_res = res.explode('allele')\n",
    "df2 = transformed_res.allele.apply(pd.Series)\n",
    "df2.columns = ['allele', 'Nreads', 'freq']\n",
    "result = pd.concat([transformed_res[transformed_res.columns[:-1]], df2], axis=1)\n",
    "result.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4b86eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = os.path.join(r\"\\PRJEB56841\\clair3_vcf\", \"summary_table_vcf.csv\")\n",
    "result.to_csv(outfile, sep='\\t', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c685f242",
   "metadata": {},
   "source": [
    "### for dRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7278a1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ERR10513574': 'MPOX_dRNA_inf_pass.bam', 'ERR10963128': 'MPOX_dRNA_inf_pass.fastq.gz'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_type</th>\n",
       "      <th>allele</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ERR10513574</th>\n",
       "      <td>bam</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10963128</th>\n",
       "      <td>fastq.gz</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            file_type allele\n",
       "ERR10513574       bam       \n",
       "ERR10963128  fastq.gz       "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_filtering_function(pair):\n",
    "    key, value = pair\n",
    "    if \"dRNA\" in value:\n",
    "        return True  # keep pair in the filtered dictionary\n",
    "    else:\n",
    "        return False  # filter pair out of the dictionary\n",
    "\n",
    "directory = r\"\\PRJEB56841\"\n",
    "\n",
    "#samples features\n",
    "## table source - DOI: 10.1038/s41597-023-02149-4\n",
    "samples_features = pd.read_excel(r\"\\PRJEB56841\\41597_2023_2149_MOESM2_ESM.xlsx\", skiprows=2)\n",
    "samples_features = samples_features.fillna(method='ffill', axis=0)\n",
    "samples_features.head()\n",
    "\n",
    "samples_features_dict = samples_features.set_index('Run accession')['File names'].to_dict()\n",
    "\n",
    "#filter mock and dRNA\n",
    "filtered_samples_features = dict(filter(my_filtering_function, samples_features_dict.items()))\n",
    "\n",
    "for key, value in filtered_samples_features.items():\n",
    "    new_value = value.split('_')[3]\n",
    "    new_value = [new_value[5:]]\n",
    "    filtered_samples_features[key] = new_value\n",
    "res = pd.DataFrame.from_dict(filtered_samples_features,orient='index', columns=['file_type'])\n",
    "res['allele'] = ''\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3622f92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_type</th>\n",
       "      <th>allele</th>\n",
       "      <th>Nreads</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ERR10513574</th>\n",
       "      <td>bam</td>\n",
       "      <td>TCT</td>\n",
       "      <td>35480.0</td>\n",
       "      <td>23.2629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10513574</th>\n",
       "      <td>bam</td>\n",
       "      <td>TCA</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>12.6355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10513574</th>\n",
       "      <td>bam</td>\n",
       "      <td>TCC</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>3.5774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10513574</th>\n",
       "      <td>bam</td>\n",
       "      <td>TCG</td>\n",
       "      <td>11526.0</td>\n",
       "      <td>13.0403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10513574</th>\n",
       "      <td>bam</td>\n",
       "      <td>*</td>\n",
       "      <td>13914.0</td>\n",
       "      <td>12.3461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10963128</th>\n",
       "      <td>fastq.gz</td>\n",
       "      <td>TCT</td>\n",
       "      <td>34670.0</td>\n",
       "      <td>22.6684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10963128</th>\n",
       "      <td>fastq.gz</td>\n",
       "      <td>TCA</td>\n",
       "      <td>8266.0</td>\n",
       "      <td>12.6514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10963128</th>\n",
       "      <td>fastq.gz</td>\n",
       "      <td>TCC</td>\n",
       "      <td>1727.0</td>\n",
       "      <td>3.6897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10963128</th>\n",
       "      <td>fastq.gz</td>\n",
       "      <td>TCG</td>\n",
       "      <td>11528.0</td>\n",
       "      <td>13.0198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR10963128</th>\n",
       "      <td>fastq.gz</td>\n",
       "      <td>*</td>\n",
       "      <td>15724.0</td>\n",
       "      <td>12.4549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            file_type allele   Nreads     freq\n",
       "ERR10513574       bam    TCT  35480.0  23.2629\n",
       "ERR10513574       bam    TCA   8256.0  12.6355\n",
       "ERR10513574       bam    TCC   1721.0   3.5774\n",
       "ERR10513574       bam    TCG  11526.0  13.0403\n",
       "ERR10513574       bam      *  13914.0  12.3461\n",
       "ERR10963128  fastq.gz    TCT  34670.0  22.6684\n",
       "ERR10963128  fastq.gz    TCA   8266.0  12.6514\n",
       "ERR10963128  fastq.gz    TCC   1727.0   3.6897\n",
       "ERR10963128  fastq.gz    TCG  11528.0  13.0198\n",
       "ERR10963128  fastq.gz      *  15724.0  12.4549"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf_dir = r\"\\PRJEB56841\\clair3_vcf\\vcf\"\n",
    "\n",
    "for key in filtered_samples_features:\n",
    "    VCF_FILE = os.path.join(vcf_dir, key+'.vcf')\n",
    "    res.loc[key]['allele'] = Nread_freq_by_category(VCF_FILE)\n",
    "\n",
    "#transform table\n",
    "transformed_res = res.explode('allele')\n",
    "df2 = transformed_res.allele.apply(pd.Series)\n",
    "df2.columns = ['allele', 'Nreads', 'freq']\n",
    "result = pd.concat([transformed_res[transformed_res.columns[:-1]], df2], axis=1)\n",
    "result.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa598cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = os.path.join(r\"\\clair3_vcf\", \"summary_table_vcf_dRNA.csv\")\n",
    "result.to_csv(outfile, sep='\\t', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af9231c",
   "metadata": {},
   "source": [
    "Table with N reads and alelle frequence by motifs for dRNA samples is located in \n",
    "output_files/summary_table_vcf.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3c8d35",
   "metadata": {},
   "source": [
    "The tables are visualized using R - MPXV_vcf.Rmd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ce92d0",
   "metadata": {},
   "source": [
    "## Simulations\n",
    "\n",
    "<a name='simulation'></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cc24a3",
   "metadata": {},
   "source": [
    "### Visualization of shares of real and simulated positions with mutations from potential ones\n",
    "\n",
    "<a name='shares'></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ab4414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('simulations_shares.csv', sep='\\t', names=['time', 'replica', 'file_type', 'motif', '#simulation', 'N mutations', 'N mutations/N potential targets'], index_col=0)\n",
    "df = df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70750d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y - the proportion of the number of mutations in the genome of the number of potential mutations\n",
    "colors_list = ['#C6878F', '#3D405B', '#81B29A', '#E07A5F', '#5F797B', '#F2CC8F']\n",
    "generation_colors = ['#678e7b', '#74a08a', \"#81b29a\", '#8db9a4', '#9ac1ae', '#a6c9b8', '#b3d0c2', '#c0d8cc', '#cce0d6', '#d9e7e0']\n",
    "my_palette = ['#E07A5F']+generation_colors\n",
    "\n",
    "for file_type in ['fastq.gz', 'bam']:\n",
    "    outfile = \"simulations_shares_\"+file_type+\".png\"\n",
    "    df2 = df[df['file_type']==file_type]\n",
    "    df2 = df2[df2['replica']!='dRNA']\n",
    "    plot = sns.relplot(data=df2, x=\"time\", y=\"N mutations/N potential targets\",\n",
    "                hue=\"#simulation\", col=\"motif\", col_order=['TCT', 'TCA', 'TCC', 'TCG'], row=\"replica\",\n",
    "                height=3, aspect=.7, kind=\"line\", palette=my_palette, alpha=1)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plot.savefig(outfile, dpi=800) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf848f0e",
   "metadata": {},
   "source": [
    "for dRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d3ebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y - the proportion of the number of mutations in the genome of the number of potential mutations\n",
    "colors_list = ['#C6878F', '#3D405B', '#81B29A', '#E07A5F', '#5F797B', '#F2CC8F']\n",
    "generation_colors = ['#678e7b', '#74a08a', \"#81b29a\", '#8db9a4', '#9ac1ae', '#a6c9b8', '#b3d0c2', '#c0d8cc', '#cce0d6', '#d9e7e0'][::-1]\n",
    "my_palette = ['#E07A5F']+generation_colors\n",
    "\n",
    "for file_type in ['fastq.gz', 'bam']:\n",
    "    outfile = \"simulations_shares_dRNA_\"+file_type+\".png\"\n",
    "    df2 = df[df['file_type']==file_type]\n",
    "    df2 = df2[df2['replica']=='dRNA']\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plot = sns.scatterplot(data=df2, x=\"motif\", y=\"N mutations/N potential targets\",\n",
    "                hue=\"#simulation\", palette=my_palette, legend=False)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig(outfile, dpi=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4a1b6d",
   "metadata": {},
   "source": [
    "### Visualization of real and simulated number of reads for targets positions by replica and time\n",
    "\n",
    "<a name='sim_Nreads'></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bcd396",
   "metadata": {},
   "source": [
    "process file simulations_Nreads_positions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59338570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def my_filtering_function(pair):\n",
    "    key, value = pair\n",
    "    if \"mock\" in value:\n",
    "        return False  # filter pair out of the dictionary\n",
    "    else:\n",
    "        return True  # keep pair in the filtered dictionary\n",
    "\n",
    "## motifs\n",
    "motif_list = ['TCT', 'TCA', 'TCC', 'TCG']\n",
    "\n",
    "## samples features\n",
    "samples_features = pd.read_excel(\"41597_2023_2149_MOESM2_ESM.xlsx\", skiprows=2)\n",
    "samples_features = samples_features.fillna(method='ffill', axis=0)\n",
    "\n",
    "samples_features_dict = samples_features.set_index('Run accession')['File names'].to_dict()\n",
    "\n",
    "### filter mock\n",
    "filtered_samples_features = dict(filter(my_filtering_function, samples_features_dict.items()))\n",
    "samples_list = filtered_samples_features.keys()\n",
    "\n",
    "### LIST WITH SAMPLES FEATURES\n",
    "time_group_file_sample = dict()\n",
    "for key, value in filtered_samples_features.items():\n",
    "    new_value = value.split('_')[2:]\n",
    "    try:\n",
    "        new_value[2] = new_value[2][5:]\n",
    "    except: #dRNA\n",
    "        time = '-'\n",
    "        group = 'dRNA'\n",
    "        file_type = new_value[1][5:]\n",
    "        new_feature = time+'_'+group+'_'+file_type\n",
    "    else:\n",
    "        new_feature = '_'.join(new_value)\n",
    "    time_group_file_sample[key] = new_feature\n",
    "\n",
    "\n",
    "# read dataframe with N reads for simulations\n",
    "Nreads_pos_df = pd.read_csv('simulations_Nreads_positions.csv', sep=',', header=None)\n",
    "Nreads_pos_df['sample_id'] = Nreads_pos_df.apply(lambda row: row[0].split(\"\\t\")[0], axis = 1)\n",
    "Nreads_pos_df['motif'] = Nreads_pos_df.apply(lambda row: row[0].split(\"\\t\")[1], axis = 1)\n",
    "Nreads_pos_df['feature'] = Nreads_pos_df.apply(lambda row: row[0].split(\"\\t\")[2], axis = 1)\n",
    "\n",
    "pos_df = Nreads_pos_df[Nreads_pos_df['feature'] == 'targets_coordinates']\n",
    "pos_df = pos_df.reset_index(drop=True)\n",
    "Nreads_df = Nreads_pos_df[Nreads_pos_df['feature'] != 'targets_coordinates']\n",
    "Nreads_df = Nreads_df.reset_index(drop=True)\n",
    "for row in range(0, len(Nreads_df)):\n",
    "    sample = Nreads_df.loc[row, \"sample_id\"]\n",
    "    motif = Nreads_df.loc[row, \"motif\"]\n",
    "    feature = Nreads_df.loc[row, \"feature\"]\n",
    "    Nreads_list = Nreads_df.loc[row, 0].split(\"\\t\")\n",
    "    Nreads_list = Nreads_list[3:]\n",
    "    Nreads_list = list(map(int, Nreads_list))\n",
    "    \n",
    "    sample_features = time_group_file_sample[sample].split(\"_\")\n",
    "    time, group, file_type = sample_features[0], sample_features[1], sample_features[2]\n",
    "    \n",
    "    ## find targets_coordinates for these sample and motif\n",
    "    pos_df_sample = pos_df[pos_df['sample_id'] == sample]\n",
    "    pos_df_sample_motif = pos_df_sample[pos_df_sample['motif'] == motif]\n",
    "    pos_df_sample_motif = pos_df_sample_motif.reset_index(drop=True)\n",
    "    pos_list = pos_df_sample_motif.loc[0, 0].split(\"\\t\")\n",
    "    pos_list = pos_list[3:]\n",
    "    pos_list = list(map(int, pos_list))\n",
    "    \n",
    "    ## create new df for these sample, motif and feature and then combine with df\n",
    "    new_dict = {'position': pos_list, 'motif': [motif]*len(pos_list),\n",
    "                        'feature': [feature]*len(pos_list), 'Nreads':Nreads_list, \n",
    "                        'time': [time]*len(pos_list), 'group': [group]*len(pos_list), \n",
    "                        'file_type': [file_type]*len(pos_list)}\n",
    "    df_new = pd.DataFrame(data=new_dict)\n",
    "    df_new.to_csv(\"result.csv\", sep='\\t', index=False, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1df6298",
   "metadata": {},
   "source": [
    "plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4185342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_list = ['#C6878F', '#3D405B', '#81B29A', '#E07A5F', '#5F797B', '#F2CC8F']\n",
    "def plot(df, file_type, my_palette=colors_list):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    df2 = df[df['file_type']==file_type]\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plot = sns.relplot(data=df2, x=\"position\", y=\"Nreads\",\n",
    "                hue=\"time\", style=\"feature\", col=\"replica\", row=\"motif\",\n",
    "                height=3, aspect=1.2, kind=\"scatter\", palette=my_palette)\n",
    "    #plt.yscale('log')\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5fdca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('result.csv', sep='\\t', names=['position', 'motif', 'feature', 'Nreads', 'time', 'group', 'file_type'])\n",
    "df = df[(df['feature']=='Nreads_mutated_sample') | (df['feature']=='Nreads_generation_1')]\n",
    "df = df[df['Nreads']!=0]\n",
    "df = df[df['group']!='dRNA']\n",
    "df = df.replace('Nreads_mutated_sample', 'sample')\n",
    "df = df.replace('Nreads_generation_1', 'simulation')\n",
    "df =df.rename(columns={\"group\": \"replica\"})\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4899612",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_type in ['bam', 'fastq.gz']:\n",
    "    f = plot(df, file_type)\n",
    "    outfile = \"simulations_Nreads_\"+file_type+\".png\"\n",
    "    f.savefig(outfile, dpi=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc99d399",
   "metadata": {},
   "source": [
    "dRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e0f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_list = ['#5F797B', '#F2CC8F']\n",
    "def plot(df, file_type, my_palette=colors_list):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    df2 = df[df['file_type']==file_type]\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plot = sns.relplot(data=df2, x=\"position\", y=\"Nreads\",\n",
    "                hue=\"feature\", col=\"motif\", col_wrap=2,\n",
    "                height=3, aspect=2, kind=\"scatter\", palette=my_palette)\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58a4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('result.csv', sep='\\t', names=['position', 'motif', 'feature', 'Nreads', 'time', 'group', 'file_type'])\n",
    "df = df[(df['feature']=='Nreads_mutated_sample') | (df['feature']=='Nreads_generation_1')]\n",
    "df = df[df['Nreads']!=0]\n",
    "df = df[df['group']=='dRNA']\n",
    "df = df.replace('Nreads_mutated_sample', 'sample')\n",
    "df = df.replace('Nreads_generation_1', 'simulation')\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99154e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_type in ['bam', 'fastq.gz']:\n",
    "    f = plot(df, file_type)\n",
    "    outfile = \"simulations_Nreads_dRNA_\"+file_type+\".png\"\n",
    "    f.savefig(outfile, dpi=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f94b33",
   "metadata": {},
   "source": [
    "### Get positions with the greatest and the least number of reads in real sample\n",
    "\n",
    "<a name='greatest_pos'></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8ac129",
   "metadata": {},
   "source": [
    "#### Positions with the greatest number of reads in real sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d2f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('result.csv', sep='\\t', names=['position', 'motif', 'feature', 'Nreads', 'time', 'group', 'file_type'])\n",
    "df = df[(df['feature']=='Nreads_mutated_sample') | (df['feature']=='Nreads_generation_1')]\n",
    "df = df[df['group']!='dRNA']\n",
    "df = df.replace('Nreads_mutated_sample', 'sample')\n",
    "df = df.replace('Nreads_generation_1', 'simulation')\n",
    "df =df.rename(columns={\"group\": \"replica\"})\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "outfile = 'position_with_the_greatest_Nreads.csv'\n",
    "with open(outfile, 'w') as fout:\n",
    "    for file_type in ['bam', 'fastq.gz']:\n",
    "        df_filetype = df[df['file_type']==file_type]\n",
    "        fout.write(file_type+'\\n')\n",
    "        for motif in ['TCT', 'TCA', 'TCC', 'TCG']:\n",
    "            df_motif = df_filetype[df_filetype['motif']==motif]\n",
    "            fout.write(motif+'\\n')\n",
    "            for replica in ['A', 'B', 'C']:\n",
    "                df_replica = df_motif[df_motif['replica']==replica]\n",
    "                fout.write(replica+'\\n')\n",
    "                fout.write('position:Nreads_sample:Nreads_simulation\\n')\n",
    "                time_dict = dict()\n",
    "                for time in ['1h', '2h', '4h', '6h', '12h', '24h']:\n",
    "                    df_time = df_replica[df_replica['time']==time]\n",
    "                    \n",
    "                    df_sample = df_time[df_time['feature']=='sample']\n",
    "                    df_simulation = df_time[df_time['feature']=='simulation']\n",
    "                    df_simulation = df_simulation.reset_index(drop=True)\n",
    "                    df_sample_sort = df_sample.sort_values(by='Nreads', ascending=False)\n",
    "                    df_sample_sort = df_sample_sort.reset_index(drop=True)\n",
    "                    \n",
    "                    time_dict[time] = [df_sample_sort['position'].tolist()[:10], df_sample_sort['Nreads'].tolist()[:10]]\n",
    "                fout.write('\\t'.join(['1h', '2h', '4h', '6h', '12h', '24h'])+'\\n')\n",
    "                for i in range(0,10):\n",
    "                    for time in ['1h', '2h', '4h', '6h', '12h', '24h']:\n",
    "                        pos = time_dict[time][0][i]\n",
    "                        Nreads_sample = time_dict[time][1][i]\n",
    "                        pos_row_ind_simulation = df_simulation.index[df_simulation['position'] == pos]\n",
    "                        Nreads_simulation = df_simulation.loc[pos_row_ind_simulation[0], 'Nreads']\n",
    "                        fout.write(str(pos)+':'+str(Nreads_sample)+':'+str(Nreads_simulation))\n",
    "                        if time == '24h':\n",
    "                            fout.write('\\n')\n",
    "                        else:\n",
    "                            fout.write('\\t')\n",
    "                fout.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1a14fa",
   "metadata": {},
   "source": [
    "#### Positions with the greatest number of reads in simulated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4045c3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('result.csv', sep='\\t', names=['position', 'motif', 'feature', 'Nreads', 'time', 'group', 'file_type'])\n",
    "df = df[(df['feature']=='Nreads_mutated_sample') | (df['feature']=='Nreads_generation_1')]\n",
    "df = df[df['group']!='dRNA']\n",
    "df = df.replace('Nreads_mutated_sample', 'sample')\n",
    "df = df.replace('Nreads_generation_1', 'simulation')\n",
    "df =df.rename(columns={\"group\": \"replica\"})\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "outfile = 'position_with_the_least_Nreads.csv'\n",
    "with open(outfile, 'w') as fout:\n",
    "    for file_type in ['bam', 'fastq.gz']:\n",
    "        df_filetype = df[df['file_type']==file_type]\n",
    "        fout.write(file_type+'\\n')\n",
    "        for motif in ['TCT', 'TCA', 'TCC', 'TCG']:\n",
    "            df_motif = df_filetype[df_filetype['motif']==motif]\n",
    "            fout.write(motif+'\\n')\n",
    "            for replica in ['A', 'B', 'C']:\n",
    "                df_replica = df_motif[df_motif['replica']==replica]\n",
    "                fout.write(replica+'\\n')\n",
    "                fout.write('position:Nreads_sample:Nreads_simulation\\n')\n",
    "                time_dict = dict()\n",
    "                for time in ['1h', '2h', '4h', '6h', '12h', '24h']:\n",
    "                    df_time = df_replica[df_replica['time']==time]\n",
    "                    \n",
    "                    df_sample = df_time[df_time['feature']=='sample']\n",
    "                    df_sample = df_sample.reset_index(drop=True)\n",
    "                    df_simulation = df_time[df_time['feature']=='simulation']\n",
    "                    \n",
    "                    df_simulation_sort = df_simulation.sort_values(by='Nreads', ascending=False)\n",
    "                    df_simulation_sort = df_simulation_sort.reset_index(drop=True)\n",
    "                    \n",
    "                    time_dict[time] = [df_simulation_sort['position'].tolist()[:20], df_simulation_sort['Nreads'].tolist()[:20]]\n",
    "                fout.write('\\t'.join(['1h', '2h', '4h', '6h', '12h', '24h'])+'\\n')\n",
    "                for i in range(0,20):\n",
    "                    for time in ['1h', '2h', '4h', '6h', '12h', '24h']:\n",
    "                        pos = time_dict[time][0][i]\n",
    "                        Nreads_simulation = time_dict[time][1][i]\n",
    "                        pos_row_ind_sample = df_sample.index[df_sample['position'] == pos]\n",
    "                        Nreads_sample = df_sample.loc[pos_row_ind_sample[0], 'Nreads']\n",
    "                        fout.write(str(pos)+':'+str(Nreads_sample)+':'+str(Nreads_simulation))\n",
    "                        if time == '24h':\n",
    "                            fout.write('\\n')\n",
    "                        else:\n",
    "                            fout.write('\\t')\n",
    "                fout.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
